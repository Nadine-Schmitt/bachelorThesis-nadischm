{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequeny of words from KORE dataset of the entity input corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [CountWords_Entity.py](https://github.com/Nadine-Schmitt/bachelorThesis-nadischm/blob/master/Code/CountWords_Entity.py) script.\n",
    "\n",
    "For each entity from the KORE datatset the number of occurence in the entity input corpus is calculated and printed as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pickle](https://docs.python.org/3/library/pickle.html), [argparse](https://docs.python.org/3/library/argparse.html), [os](https://docs.python.org/2/library/os.html) and [gensim](https://radimrehurek.com/gensim/) are needed for this script to work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import argparse\n",
    "import os\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage of the script can be seen with the default -h or --help flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.17134.885]\r\n",
      "(c) 2018 Microsoft Corporation. Alle Rechte vorbehalten.\r\n",
      "\r\n",
      "(base) C:\\Users\\nadin\\Documents\\Bachelorarbeit\\Code>python CountWords_Entity.py --help\n",
      "usage: CountWords_Entity.py [-h] koreSource inputSource\r\n",
      "\r\n",
      "Script for translating wikipedia page names\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  koreSource   source folder with kore dataset\r\n",
      "  inputSource  source folder with inputlist entity\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help   show this help message and exit\r\n",
      "\r\n",
      "(base) C:\\Users\\nadin\\Documents\\Bachelorarbeit\\Code>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "python CountWords_Entity.py --help\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underscore_creator() take an entity (e.g. Apple Inc.) and transform it into its id (Apple_Inc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def underscore_creator(s): \n",
    "    w = ''\n",
    "    l = s.split(' ')\n",
    "    for index in range(len(l) -1): \n",
    "        w += l[index] + '_'\n",
    "    w += l[-1]\n",
    "    return w "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read KORE dataset into list and transform entities into their id with the underscore-creator():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readKore(source):\n",
    "    \n",
    "    list = [line.rstrip('\\n') for line in open(source, encoding=\"UTF-8\")]\n",
    "   \n",
    "    lenght = len(list)\n",
    "        for index in range(lenght):\n",
    "        if list[index][0] == \"\\t\":\n",
    "            list[index] = list[index][1:len(list[index])]\n",
    "    #entity: words with underscore\n",
    "    listUnderscore = []\n",
    "    for e in list:\n",
    "        eNew = underscore_creator(e)\n",
    "        listUnderscore.append(eNew)\n",
    "            \n",
    "    return listUnderscore\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function reads the inputList entity file by file and for each word from the KORE dataset the number of occurence is calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadInputList(dirname, KoreList):\n",
    "    counterList = []\n",
    "    i = 0\n",
    "    while i < len(KoreList):\n",
    "        counterList.append(0)\n",
    "        i = i+1\n",
    "    loadSentence = []\n",
    "    filenames = [f.path for f in os.scandir(dirname) ]\n",
    "    for fname in filenames:\n",
    "        print(\"read sentences from \", fname)\n",
    "        loadSentence = []\n",
    "        with open(fname, 'r') as f:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                words = line.split()\n",
    "                for w in words:\n",
    "                    loadSentence.append(w)\n",
    "                line = f.readline()\n",
    "            #print(loadSentence)\n",
    "            #count words\n",
    "            iterator = 0\n",
    "            for e in KoreList:\n",
    "                #print(e)\n",
    "                counterList[iterator] += loadSentence.count(e)\n",
    "                iterator = iterator +1\n",
    "                \n",
    "    return counterList     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Script for translating wikipedia page names')\n",
    "parser.add_argument('koreSource', type=str, help='source folder with kore dataset')\n",
    "parser.add_argument('inputSource', type=str, help='source folder with inputlist entity')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read Kore data\n",
    "KoreList = readKore(args.koreSource)\n",
    "KoreList[0] ='Apple'\n",
    "for e in KoreList:\n",
    "    print(e) #print all words from Kore\n",
    "count = loadInputList(args.inputSource,KoreList)\n",
    "for e in count:\n",
    "    print(e) #print afterwards their occurence\n",
    "#print(KoreList[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Jupyter Notebook into py-script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script CountWords_Entity.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
