{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate word and entity embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [main.py](https://github.com/Nadine-Schmitt/bachelorThesis-nadischm/blob/master/Code/main.py) script.\n",
    "\n",
    "The script trains word and entity emebddings with [Gensim's Word2Vec libary](https://radimrehurek.com/gensim/models/word2vec.html). The raw and entity model is evaluated directly after training, because the models are to big to be saved on a disk and reloaded on a later point in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[gensim](https://radimrehurek.com/gensim/), [argparse](https://docs.python.org/3/library/argparse.html), [multiprocessing](https://docs.python.org/3.4/library/multiprocessing.html?highlight=process), [numpy](https://numpy.org/), [pandas](https://pandas.pydata.org/), [pickle](https://docs.python.org/3/library/pickle.html), [time](https://docs.python.org/3/library/time.html) and [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html) are needed for this script to work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage of the script can be seen with the default -h or --help flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.17134.885]\r\n",
      "(c) 2018 Microsoft Corporation. Alle Rechte vorbehalten.\r\n",
      "\r\n",
      "(base) C:\\Users\\nadin\\Documents\\Bachelorarbeit\\Code>python main.py --help\n",
      "usage: main.py [-h] [-t THREADS]\r\n",
      "               sourceRaw sourceEntity goldData iterations paraList\r\n",
      "\r\n",
      "Script for training word embeddings\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  sourceRaw             source folder with preprocessed raw data\r\n",
      "  sourceEntity          source folder with preprocessed entity data\r\n",
      "  goldData              directory where to find the gold lists for the\r\n",
      "                        evaluation models\r\n",
      "  iterations            how often train model for each parameter set\r\n",
      "  paraList              source folder of paraList\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -t THREADS, --threads THREADS\r\n",
      "                        number of worker threads to train the model\r\n",
      "\r\n",
      "(base) C:\\Users\\nadin\\Documents\\Bachelorarbeit\\Code>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "python main.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following function calculates the cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    temp = x / np.linalg.norm(x, ord=2)\n",
    "    temp2 = y / np.linalg.norm(y, ord=2)\n",
    "    return np.dot(temp, temp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the Pairwise Accuracy between the gold standard rank and the model-produced rank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_accuracy(golds, preds):\n",
    "    count_good = 0.0\n",
    "    count_all = 0.0\n",
    "    for i in range(len(golds) - 1):\n",
    "        for j in range(i+1, len(golds)):\n",
    "            count_all += 1.0\n",
    "            diff_gold = golds[i] - golds[j]\n",
    "            diff_pred = preds[i] - preds[j]\n",
    "            if (diff_gold * diff_pred >= 0):\n",
    "                count_good += 1.0\n",
    "    return count_good / count_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underscore_creator() take an entity (e.g. Apple Inc.) and transform it into its id (Apple_Inc.). \n",
    "It is needed in the evaKoreEntity-function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def underscore_creator(s): \n",
    "    w = ''\n",
    "    l = s.split(' ')\n",
    "    for index in range(len(l) -1): \n",
    "        w += l[index] + '_'\n",
    "    w += l[-1]\n",
    "    return w    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following function removes brackets and is used in the EvaKoreRaw-function.\n",
    "For example _Cell (microprocessor)_ is going to be _Cell microprocessor_ (just calculating the 2 vectors without the brackets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeBrackets(word):\n",
    "    if word[0] == '(':\n",
    "        word = word[1: len(word)]\n",
    "    if word[len(word)-1] == ')':\n",
    "        word = word[:len(word)-1]\n",
    "    #print(word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the cosine similarity between two word vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_cosine_calculator(x, y, trained_model): \n",
    "    if x in trained_model.wv.vocab and y in trained_model.wv.vocab:\n",
    "        vector_1 = trained_model[x]\n",
    "        vector_2 = trained_model[y]\n",
    "        cosine = cosine_similarity(vector_1, vector_2)\n",
    "    else:\n",
    "        cosine = 0\n",
    "    \n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getKoreData() reads the entities from the KORE dataset into a dictionary:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get KORE-data in dictionary\n",
    "def getKoreData(datafile):\n",
    "    #\n",
    "\n",
    "    lines = [line.rstrip('\\n') for line in open(datafile)]\n",
    "    lines[0] = 'Apple Inc.'\n",
    "    lines[195] = '\\tGolden Globe Award for Best Actor - Motion Picture Drama' #instead of Golden Globe Award for Best Actor â€“ Motion Picture Drama\n",
    "    lines[299]= '\\tKärtsy Hatakka' #instead of KÃ¤rtsy Hatakka\n",
    "    lines[302]= '\\tRagnarök' #instead of RagnarÃ¶k\n",
    "\n",
    "    Kore_dict = dict()\n",
    "    start_parameter = 1\n",
    "    end_parameter = 21\n",
    "    for i in range(21): \n",
    "        word = lines[start_parameter -1]\n",
    "        Kore_dict[word] = []\n",
    "    \n",
    "        for k in range(start_parameter,end_parameter): \n",
    "            w = lines[k][1:]\n",
    "            Kore_dict[word].append(w)\n",
    "        start_parameter += 21\n",
    "        end_parameter += 21\n",
    "    return Kore_dict\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions evaluate the trained models with a gold standard. The evaSim353() uses the Similarity353 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Similarity-353\n",
    "def evaSim353(sim353_data, model):\n",
    "    \n",
    "    #read file\n",
    "    data_sim353 = pd.read_table(sim353_data, header = None, names=('Col1', 'Col2', 'Col3'))\n",
    "\n",
    "    #add cosine similarity\n",
    "    data_sim353['Word2Vec_Cosine'] = data_sim353[['Col1','Col2']].apply(lambda row: word2vec_cosine_calculator(*row, model), axis=1)\n",
    "    data_return = data_sim353['Word2Vec_Cosine']\n",
    "\n",
    "    #calculate pearson, spearman\n",
    "    pearson_sim353 = pearsonr(data_sim353['Col3'], data_sim353['Word2Vec_Cosine'])\n",
    "    spearman_sim353, p_value_sim353 = spearmanr(data_sim353['Col3'], data_sim353['Word2Vec_Cosine'])\n",
    "    #print(\"Pearson Sim-353: \", pearson_sim353)\n",
    "    #print(\"Spearman Sim-353: \" , spearman_sim353, p_value_sim353)\n",
    "    return [pearson_sim353[0], pearson_sim353[1], spearman_sim353, p_value_sim353], data_return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with Relatedness353 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Relatedness-353\n",
    "def evaRel353(rel353_data, model):\n",
    "    \n",
    "    #read file\n",
    "    data_rel353 = pd.read_table(rel353_data, header = None, names=('Col1', 'Col2', 'Col3'))\n",
    "    #data_rel353.head()\n",
    "\n",
    "    #add cosine similarity\n",
    "    data_rel353['Word2Vec_Cosine'] = data_rel353[['Col1','Col2']].apply(lambda row: word2vec_cosine_calculator(*row, model), axis=1)\n",
    "    data_return = data_rel353['Word2Vec_Cosine']   \n",
    "\n",
    "    #calculate pearson, spearman\n",
    "    pearson_rel353 = pearsonr(data_rel353['Col3'], data_rel353['Word2Vec_Cosine'])\n",
    "    spearman_rel353, p_value_rel353 = spearmanr(data_rel353['Col3'], data_rel353['Word2Vec_Cosine'])\n",
    "    #print(\"Pearson Rel-353: \", pearson_rel353)\n",
    "    #print(\"Spearman Rel-353: \" , spearman_rel353, p_value_rel353)\n",
    "    return [pearson_rel353[0], pearson_rel353[1], spearman_rel353, p_value_rel353], data_return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with MEN dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MEN\n",
    "def evaMen(men_data, model):\n",
    "    \n",
    "    #read file\n",
    "    data_men = pd.read_table(men_data, sep = \" \", header = None, names=('Col1', 'Col2', 'Col3'))\n",
    "    #print(data_men.head())\n",
    "\n",
    "    #add cosine similarity\n",
    "    data_men['Word2Vec_Cosine'] = data_men[['Col1','Col2']].apply(lambda row: word2vec_cosine_calculator(*row, model), axis=1)\n",
    "    data_return = data_men['Word2Vec_Cosine']\n",
    "    #data_men\n",
    "\n",
    "    #calculate pearson, spearman\n",
    "    pearson_men = pearsonr(data_men['Col3'], data_men['Word2Vec_Cosine'])\n",
    "    spearman_men, p_value_men = spearmanr(data_men['Col3'], data_men['Word2Vec_Cosine'])\n",
    "    #print(\"Pearson MEN: \", pearson_men)\n",
    "    #print(\"Spearman MEN: \" , spearman_men, p_value_men)\n",
    "    return [pearson_men[0], pearson_men[1], spearman_men, p_value_men], data_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with RG65 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###RG65\n",
    "def evaRG65(RG65_data, model):\n",
    "\n",
    "    #read file\n",
    "    data_rg65 = pd.read_table(RG65_data, sep = \";\", header = None, names=('Col1', 'Col2', 'Col3'))\n",
    "    #print(data_rg65)\n",
    "\n",
    "    #add cosine similarity\n",
    "    data_rg65['Word2Vec_Cosine'] = data_rg65[['Col1','Col2']].apply(lambda row: word2vec_cosine_calculator(*row, model), axis=1)\n",
    "    data_return = data_rg65['Word2Vec_Cosine']\n",
    "    #data_men\n",
    "\n",
    "    #calculate pearson, spearman\n",
    "    pearson_rg65 = pearsonr(data_rg65['Col3'], data_rg65['Word2Vec_Cosine'])\n",
    "    spearman_rg65, p_value_rg65 = spearmanr(data_rg65['Col3'], data_rg65['Word2Vec_Cosine'])\n",
    "    #print(\"Pearson RG65: \", pearson_rg65)\n",
    "    #print(\"Spearman RG65: \" , spearman_rg65, p_value_rg65)\n",
    "    return [pearson_rg65[0], pearson_rg65[1], spearman_rg65, p_value_rg65], data_return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with MTurk dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MTurk\n",
    "def evaMTurk(MTurk_data, model):\n",
    "\n",
    "    #read file\n",
    "    data_mturk = pd.read_table(MTurk_data, sep = \",\", header= None, names=('Col1', 'Col2', 'Col3'))\n",
    "    #print(data_mturk.head())\n",
    "\n",
    "    #add cosine similarity\n",
    "    data_mturk['Word2Vec_Cosine'] = data_mturk[['Col1','Col2']].apply(lambda row: word2vec_cosine_calculator(*row, model), axis=1)\n",
    "    data_return = data_mturk['Word2Vec_Cosine']\n",
    "    #data_mturk\n",
    "\n",
    "    #calculate pearson, spearman\n",
    "    pearson_mturk = pearsonr(data_mturk['Col3'], data_mturk['Word2Vec_Cosine'])\n",
    "    spearman_mturk, p_value_mturk = spearmanr(data_mturk['Col3'], data_mturk['Word2Vec_Cosine'])\n",
    "    #print(\"Pearson MTurk: \", pearson_mturk)\n",
    "    #print(\"Spearman MTurk: \" , spearman_mturk, p_value_mturk)\n",
    "    return [pearson_mturk[0], pearson_mturk[1], spearman_mturk, p_value_mturk], data_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with SimLe999 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###SimLex999\n",
    "def evaSimLex999(SimLex999_data, model):\n",
    "    \n",
    "    #read file\n",
    "    data_simlex = pd.read_table(SimLex999_data, sep = \"\\t\", header = None, names=('word1', 'word2', 'POS', 'SimLex999', 'conc(w1)', 'conc(w2)', 'concQ', 'Assoc(USF)', 'SimAssoc333', 'SD(SimLex)'))\n",
    "    #print(data_simlex)\n",
    "\n",
    "    #add cosine similarity\n",
    "    data_simlex['Word2Vec_Cosine'] = data_simlex[['word1','word2']].apply(lambda row: word2vec_cosine_calculator(*row, model), axis=1)\n",
    "    data_return = data_simlex['Word2Vec_Cosine']\n",
    "    #print(data_simlex)\n",
    "\n",
    "    #calculate pearson, spearman\n",
    "    pearson_simlex= pearsonr(data_simlex['SimLex999'], data_simlex['Word2Vec_Cosine'])\n",
    "    spearman_simlex, p_value_simlex = spearmanr(data_simlex['SimLex999'], data_simlex['Word2Vec_Cosine'])\n",
    "    #print(\"Pearson SimLex999: \", pearson_simlex)\n",
    "    #print(\"Spearman Simlex999: \" , spearman_simlex, p_value_simlex)\n",
    "    return [pearson_simlex[0], pearson_simlex[1], spearman_simlex, p_value_simlex], data_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with RareWord dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Rareword\n",
    "def evaRareWord(RareWord_data, model):\n",
    "    \n",
    "    #read file\n",
    "    data_rare = pd.read_table(RareWord_data, sep = \"\\t\", header = None, names=('word1', 'word2', 'average', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'))\n",
    "    #print(data_rare)\n",
    "\n",
    "    #add cosine similarity\n",
    "    data_rare['Word2Vec_Cosine'] = data_rare[['word1','word2']].apply(lambda row: word2vec_cosine_calculator(*row, model), axis=1)\n",
    "    data_return = data_rare['Word2Vec_Cosine']\n",
    "    #print(data_rare)\n",
    "\n",
    "    #calculate pearson, spearman\n",
    "    pearson_rare= pearsonr(data_rare['average'], data_rare['Word2Vec_Cosine'])\n",
    "    spearman_rare, p_value_rare = spearmanr(data_rare['average'], data_rare['Word2Vec_Cosine'])\n",
    "    #print(\"Pearson RareWord: \", pearson_rare)\n",
    "    #print(\"Spearman Rareword: \" , spearman_rare, p_value_rare)\n",
    "    return [pearson_rare[0], pearson_rare[1], spearman_rare, p_value_rare], data_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the raw model with the KORE dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate KORE for RAW corpus\n",
    "def evaKoreRaw(kore_dict, model, modelSize):\n",
    "    #\n",
    "    #\n",
    "    standard_ranking = [i for i in range(1, 21)] #create list with ranking from 1 to 20\n",
    "    counter = 0\n",
    "    correlation_spearman = 0\n",
    "    correlation_pairwise = 0\n",
    "    for key, value in kore_dict.items(): #loop through dictionary\n",
    "        key_list = key.split(' ')\n",
    "        main_vector = np.zeros(modelSize)\n",
    "        for index in range(len(key_list)): \n",
    "            key_list[index] = removeBrackets(key_list[index])\n",
    "            main_vector += model[key_list[index]]\n",
    "\n",
    "        vector_dict = dict()\n",
    "        vector_list = []\n",
    "        final_list= []\n",
    "        for word in value: #loop through the list of words  \n",
    "            w_list = word.split(' ') \n",
    "            vector = np.zeros(modelSize)\n",
    "            for index in range(len(w_list)):     \n",
    "                w_list[index] = removeBrackets(w_list[index]) #remove brackets\n",
    "                if w_list[index] in model.wv.vocab: #get the vector of the main entitiy\n",
    "                    vector += model[w_list[index]]\n",
    "                else: \n",
    "                    vector += np.zeros(modelSize)\n",
    "                    #print(w_list[index])\n",
    "            cosine = cosine_similarity(main_vector, vector) #calculate the cosine similarity between main word and connected word \n",
    "            vector_dict[word] = cosine #store similarity in a dictionary: keys like Steve Jobs and cosine to Apple as value\n",
    "            vector_list.append(cosine) #list of cosine values (size 20)\n",
    "        vector_list.sort() #sort list\n",
    "        if len(vector_list) != len(set(vector_list)): #check if the list has duplicates, then a warning is printed \n",
    "            print('WARNING!!!!!!')\n",
    "        for word in value: \n",
    "            k = vector_dict[word] #getting the cosine value according to the ranking\n",
    "            rank = vector_list.index(k) +1 #get rank in the list  \n",
    "            final_list.append(rank) #append rank to fianal list\n",
    "        spearman, p_value = spearmanr(standard_ranking, final_list) #calculate spearman\n",
    "        pairwise = pairwise_accuracy(standard_ranking, final_list) #calculate pairwise accuracy\n",
    "        #print('Spearman:', spearman, p_value, 'Pairwise Accuracy', pairwise)\n",
    "        correlation_spearman += spearman\n",
    "        correlation_pairwise += pairwise\n",
    "        counter += 1\n",
    "    final_corr_spearman = correlation_spearman/counter  \n",
    "    final_corr_pairwise = correlation_pairwise/counter  \n",
    "    #print('Spearman', final_corr_spearman, 'Pairwise Accuracy', final_corr_pairwise)\n",
    "    return [final_corr_spearman, final_corr_pairwise]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the entity model with the KORE dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate KORE for Entity corpus\n",
    "def evaKoreEntity(kore_dict, model, modelSize):\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    standard_ranking = [i for i in range(1, 21)] #create list with ranking from 1 to 20\n",
    "    counter = 0\n",
    "    correlation_spearman = 0\n",
    "    correlation_pairwise = 0\n",
    "    for key, value in kore_dict.items(): #loop through dictionary\n",
    "        main_vector = model[underscore_creator(key)]\n",
    "        #print(\"entity: \" ,underscore_creator(key))\n",
    "        \n",
    "        vector_dict = dict()\n",
    "        vector_list = []\n",
    "        final_list= []\n",
    "        for word in value: #loop through the list of words  \n",
    "            w = underscore_creator(word) #connect words with underscores\n",
    "            if w in model.wv.vocab: #get vector if each word \n",
    "                vector = model[w]\n",
    "            else: \n",
    "                vector = np.zeros(modelSize)\n",
    "                #print(w)\n",
    "            cosine = cosine_similarity(main_vector, vector) #calculate the cosine similarity between main word and connected word \n",
    "            vector_dict[w] = cosine #store similarity in a dictionary: keys like Steve Jobs and cosine to Apple as value\n",
    "            vector_list.append(cosine) #list of cosine values (size 20)\n",
    "        vector_list.sort() #sirt list\n",
    "        if len(vector_list) != len(set(vector_list)): #check if the list has duplicates, then a warning is printed \n",
    "            print('WARNING!!!!!!')\n",
    "        for word in value: \n",
    "            k = vector_dict[underscore_creator(word)] #getting the cosine value according to the ranking\n",
    "            rank = vector_list.index(k)+1 #get rank in the list  \n",
    "            final_list.append(rank) #append rank to fianal list\n",
    "        spearman, p_value = spearmanr(standard_ranking, final_list) #calculate spearman\n",
    "        pairwise = pairwise_accuracy(standard_ranking, final_list) #calculate pairwise accuracy\n",
    "        #print('Spearman:', spearman, p_value, 'Pairwise Accuracy', pairwise)\n",
    "        correlation_spearman += spearman\n",
    "        correlation_pairwise += pairwise\n",
    "        counter += 1\n",
    "    final_corr_spearman = correlation_spearman/counter  \n",
    "    final_corr_pairwise = correlation_pairwise/counter  \n",
    "    #print('Spearman', final_corr_spearman, 'Pairwise Accuracy', final_corr_pairwise)\n",
    "    return [final_corr_spearman, final_corr_pairwise]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaRawEntity() calculates the Pearson score between the produced ranks from the raw and entity model. It is needed as additional input parameter for the [cocor package in R](https://cran.r-project.org/web/packages/cocor/cocor.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculate Pearson between RAW/Entity list\n",
    "def evaRawEntity(rList, eList):\n",
    "    pearson = pearsonr(rList, eList)\n",
    "    return pearson[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the parameters used in the training into text (for printing them out):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def para2text(sizeI, windowI, min_countI, sgI, hsI, negativeI, cbowmeanI):\n",
    "    para = str(sizeI) + \"/\" + str(windowI) + \"/\" + str(min_countI) + \"/\" + str(sgI) + \"/\" + str(hsI) + \"/\" + str(negativeI) + \"/\" + str(cbowmeanI)\n",
    "    return para"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following to functions transform the results into text (for printing them out):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result2text(result, pearsonRE):\n",
    "    rText = \"{0:18.16f};{1:18.16e};{2:18.16f};{3:18.16e};{4:18.16f}\".format(*result, pearsonRE)\n",
    "    return rText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result2TextShort(result):\n",
    "    rText = \"{0:18.16f};{1:18.16f}\".format(*result)\n",
    "    return rText\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "def printResult(modelType, modelP, results1, results2, results3, result4, result5, result6, result7, result8):\n",
    "    print(modelType,  modelP , results1, results2, results3, result4, result5, result6, result7, result8, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With following function the parameter setting is read. It returns a list of lists, in which each list is a parameter setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read parameter settings and get list of lists in which each list is a parameter set\n",
    "def readParaSetting(paraList):\n",
    "    finallist = []\n",
    "    lines = [line.rstrip('\\n') for line in open(paraList)]\n",
    "    #lines[-1] = lines[-1][0:len(lines[-1])-1]\n",
    "    for e in lines:\n",
    "        if len(e) > 0:\n",
    "            list =[]\n",
    "            listelements = e.split(' , ')\n",
    "            for i in listelements:\n",
    "                list.append(i)\n",
    "            finallist.append(list)\n",
    "    return finallist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "startTime = time.time()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Script for training word embeddings')\n",
    "parser.add_argument('sourceRaw', type=str, help='source folder with preprocessed raw data')\n",
    "parser.add_argument('sourceEntity', type=str, help='source folder with preprocessed entity data')\n",
    "parser.add_argument('goldData', type=str, help='directory where to find the gold lists for the evaluation models')\n",
    "parser.add_argument('iterations', type=int, default=1, help='how often train model for each parameter set')\n",
    "parser.add_argument('paraList', type=str, help='source folder of paraList')\n",
    "\n",
    "parser.add_argument('-t', '--threads', type=int, default=mp.cpu_count(), help='number of worker threads to train the model')\n",
    "args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading gold stands and input corpuses for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gold standards for word related tasks\n",
    "print(\" define goldstandard and load model input \")\n",
    "sim353_datafile = args.goldData + r\"\\wordsim_similarity_goldstandard.txt\"\n",
    "rel353_datafile = args.goldData + r\"\\wordsim_relatedness_goldstandard.txt\"\n",
    "men_datafile = args.goldData + r\"\\MEN_dataset_natural_form_full.txt\"\n",
    "rg65_datafile = args.goldData + r\"\\RG65.txt\"\n",
    "mturk_datafile = args.goldData + r\"\\MTurk.csv\"\n",
    "simlex999_datafile = args.goldData + r\"\\SimLex-999.txt\"\n",
    "rareword_datafile = args.goldData + r\"\\RareWord.txt\"\n",
    "kore_datafile = args.goldData + r\"\\Kore_entity_relatedness_processed.txt\"\n",
    "\n",
    "#using PathLineSentence\n",
    "sentencesRaw = gensim.models.word2vec.PathLineSentences(args.sourceRaw)\n",
    "sentencesEntity = gensim.models.word2vec.PathLineSentences(args.sourceEntity)\n",
    "\n",
    "#Loading Kore dataset for the entity related task\n",
    "kore_dict = getKoreData(kore_datafile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameter\n",
    "paraList = readParaSetting(args.paraList)\n",
    "\n",
    "#set number of iterations\n",
    "iterations = args.iterations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for e in paraList:\n",
    "    sgI = int(e[3])\n",
    "    if sgI == 0:\n",
    "        cbowmeanP = [0, 1]\n",
    "    else:\n",
    "        cbowmeanP = [1]\n",
    "    sizeI = int(e[0]) \n",
    "    windowI = int(e[1])\n",
    "    min_countI = int(e[2])\n",
    "    hsI = int(e[4])\n",
    "    negativeI = int(e[5])\n",
    "    for cbowmeanI in cbowmeanP:\n",
    "        lauf = 0\n",
    "        sim353ResultR = [0, 0, 0, 0]\n",
    "        sim353ResultE = [0, 0, 0, 0]\n",
    "        sim353RE = 0\n",
    "        rel353ResultR = [0, 0, 0, 0]\n",
    "        rel353ResultE = [0, 0, 0, 0]\n",
    "        rel353RE = 0\n",
    "        menResultR = [0, 0, 0, 0]\n",
    "        menResultE = [0, 0, 0, 0]\n",
    "        menRE = 0\n",
    "        rg65ResultR = [0, 0, 0, 0]\n",
    "        rg65ResultE = [0, 0, 0, 0]\n",
    "        rg65RE = 0\n",
    "        MTurkResultR = [0, 0, 0, 0]\n",
    "        MTurkResultE = [0, 0, 0, 0]\n",
    "        MTurkRE = 0\n",
    "        simlex999ResultR = [0, 0, 0, 0]\n",
    "        simlex999ResultE = [0, 0, 0, 0]\n",
    "        simlex999RE = 0\n",
    "        RareWordResultR = [0, 0, 0, 0]\n",
    "        RareWordResultE = [0, 0, 0, 0]\n",
    "        RareWordRE = 0\n",
    "                            \n",
    "        KoreResultR = [0, 0]\n",
    "        KoreResultE = [0, 0]\n",
    "        # training and evaluation is done #iteration-times and performance is averaged\n",
    "        while lauf < iterations:\n",
    "            # build the model\n",
    "            print(\"Lauf \", lauf)\n",
    "            lauf += 1\n",
    "            #mRStart = time.time()\n",
    "            modelRaw  = Word2Vec(sentencesRaw,\n",
    "                                size=sizeI,\n",
    "                                window=windowI,\n",
    "                                min_count=min_countI,\n",
    "                                workers=args.threads,\n",
    "                                sg=sgI,\n",
    "                                hs=hsI,\n",
    "                                negative=negativeI,\n",
    "                                cbow_mean=cbowmeanI)\n",
    "\n",
    "            #mREnd = time.time()\n",
    "\n",
    "            #mEStart = time.time()\n",
    "            modelEntity  = Word2Vec(sentencesEntity,\n",
    "                                size=sizeI,\n",
    "                                window=windowI,\n",
    "                                min_count=min_countI,\n",
    "                                workers=args.threads,\n",
    "                                sg=sgI,\n",
    "                                hs=hsI,\n",
    "                                negative=negativeI,\n",
    "                                cbow_mean=cbowmeanI)\n",
    "            #mEEnd = time.time()\n",
    "                            \n",
    "            #print(\"Raw    Model training time : \", mREnd - mRStart)\n",
    "            #print(\"Entity Model training time : \", mEEnd - mEStart)\n",
    "\n",
    "            #Kore Test\n",
    "            result = evaKoreRaw(kore_dict, modelRaw, sizeI)\n",
    "            for i in range(len(KoreResultR)):\n",
    "                KoreResultR[i] += result[i]\n",
    "            result = evaKoreEntity(kore_dict, modelEntity, sizeI)\n",
    "            for i in range(len(KoreResultE)):\n",
    "                KoreResultE[i] += result[i]\n",
    "                               \n",
    "            result, cosineRaw  = evaSim353(sim353_datafile, modelRaw)\n",
    "            for i in range(len(sim353ResultR)):\n",
    "                sim353ResultR[i] += result[i]\n",
    "            result, cosineEntity = evaSim353(sim353_datafile, modelEntity)\n",
    "            for i in range(len(sim353ResultE)):\n",
    "                sim353ResultE[i] += result[i]\n",
    "            sim353RE =+ evaRawEntity(cosineRaw, cosineEntity)\n",
    "\n",
    "            result, cosineRaw  = evaRel353(rel353_datafile, modelRaw)\n",
    "            for i in range(len(rel353ResultR)):\n",
    "                rel353ResultR[i] += result[i]\n",
    "            result, cosineEntity = evaRel353(rel353_datafile, modelEntity)\n",
    "            for i in range(len(rel353ResultE)):\n",
    "                 rel353ResultE[i] += result[i]\n",
    "            rel353RE =+ evaRawEntity(cosineRaw, cosineEntity)\n",
    "                                \n",
    "            result, cosineRaw  = evaMen(men_datafile, modelRaw)\n",
    "            for i in range(len(menResultR)):\n",
    "                menResultR[i] += result[i]\n",
    "            result, cosineEntity = evaMen(men_datafile, modelEntity)\n",
    "            for i in range(len(menResultE)):\n",
    "                 menResultE[i] += result[i]\n",
    "            menRE =+ evaRawEntity(cosineRaw, cosineEntity)\n",
    "                                \n",
    "            result, cosineRaw  = evaRG65(rg65_datafile, modelRaw)\n",
    "            for i in range(len(rg65ResultR)):\n",
    "                rg65ResultR[i] += result[i]\n",
    "            result, cosineEntity = evaRG65(rg65_datafile, modelEntity)\n",
    "            for i in range(len(rg65ResultE)):\n",
    "                rg65ResultE[i] += result[i]\n",
    "            rg65RE =+ evaRawEntity(cosineRaw, cosineEntity)\n",
    "                                \n",
    "            result, cosineRaw  = evaMTurk(mturk_datafile, modelRaw)\n",
    "            for i in range(len(MTurkResultR)):\n",
    "                MTurkResultR[i] += result[i]\n",
    "            result, cosineEntity = evaMTurk(mturk_datafile, modelEntity)\n",
    "            for i in range(len(MTurkResultE)):\n",
    "                MTurkResultE[i] += result[i]\n",
    "            MTurkRE =+ evaRawEntity(cosineRaw, cosineEntity)\n",
    "\n",
    "            result, cosineRaw  = evaSimLex999(simlex999_datafile, modelRaw)\n",
    "            for i in range(len(simlex999ResultR)):\n",
    "                simlex999ResultR[i] += result[i]\n",
    "            result, cosineEntity = evaSimLex999(simlex999_datafile, modelEntity)\n",
    "            for i in range(len(simlex999ResultE)):\n",
    "                simlex999ResultE[i] += result[i]\n",
    "            simlex999RE =+ evaRawEntity(cosineRaw, cosineEntity)\n",
    "\n",
    "            result, cosineRaw = evaRareWord(rareword_datafile, modelRaw)\n",
    "            for i in range(len(RareWordResultR)):\n",
    "                RareWordResultR[i] += result[i]\n",
    "            result, cosineEntity = evaRareWord(rareword_datafile, modelEntity)\n",
    "            for i in range(len(RareWordResultE)):\n",
    "                RareWordResultE[i] += result[i]\n",
    "            RareWordRE =+ evaRawEntity(cosineRaw, cosineEntity)\n",
    "                                    \n",
    "        #calc average results\n",
    "        for i in range(4):\n",
    "            sim353ResultR[i] = sim353ResultR[i] / iterations\n",
    "            sim353ResultE[i] = sim353ResultE[i] / iterations\n",
    "            sim353RE = sim353RE / iterations\n",
    "                                \n",
    "            rel353ResultR[i] = rel353ResultR[i] / iterations\n",
    "            rel353ResultE[i] = rel353ResultE[i] / iterations\n",
    "            rel353RE = rel353RE / iterations\n",
    "                                \n",
    "            menResultR[i] = menResultR[i]  / iterations\n",
    "            menResultE[i] = menResultE[i]  / iterations\n",
    "            menRE = menRE / iterations\n",
    "                                \n",
    "            rg65ResultR[i] = rg65ResultR[i] / iterations\n",
    "            rg65ResultE[i] = rg65ResultE[i] / iterations\n",
    "            rg65RE = rg65RE / iterations\n",
    "                                \n",
    "            MTurkResultR[i] = MTurkResultR[i] / iterations\n",
    "            MTurkResultE[i] = MTurkResultE[i] / iterations\n",
    "            MTurkRE = MTurkRE / iterations\n",
    "                                \n",
    "            simlex999ResultR[i] = simlex999ResultR[i] / iterations\n",
    "            simlex999ResultE[i] = simlex999ResultE[i] / iterations\n",
    "            simlex999RE = simlex999RE / iterations\n",
    "                                \n",
    "            RareWordResultR[i] = RareWordResultR[i] / iterations\n",
    "            RareWordResultE[i] = RareWordResultE[i] / iterations\n",
    "            RareWordRE = RareWordRE / iterations\n",
    "        for i in range(2):  \n",
    "            KoreResultR[i] = KoreResultR[i] / iterations\n",
    "            KoreResultE[i] = KoreResultE[i] / iterations\n",
    "                                \n",
    "        #prepare printout\n",
    "        mPara = para2text(sizeI, windowI, min_countI, sgI, hsI, negativeI, cbowmeanI)\n",
    "        r1 = result2text(sim353ResultR, sim353RE)\n",
    "        r2 = result2text(rel353ResultR, rel353RE)\n",
    "        r3 = result2text(menResultR, menRE)\n",
    "        r4 = result2text(rg65ResultR, rg65RE)\n",
    "        r5 = result2text(MTurkResultR, MTurkRE)\n",
    "        r6 = result2text(simlex999ResultR, simlex999RE)\n",
    "        r7 = result2text(RareWordResultR, RareWordRE)\n",
    "        r8 = result2TextShort(KoreResultR)\n",
    "        e1 = result2text(sim353ResultE, sim353RE)\n",
    "        e2 = result2text(rel353ResultE, rel353RE)\n",
    "        e3 = result2text(menResultE, menRE)\n",
    "        e4 = result2text(rg65ResultE, rg65RE)\n",
    "        e5 = result2text(MTurkResultE, MTurkRE)\n",
    "        e6 = result2text(simlex999ResultE, simlex999RE)\n",
    "        e7 = result2text(RareWordResultE, RareWordRE)\n",
    "        e8 = result2TextShort(KoreResultE)\n",
    "        #print it\n",
    "        printResult(\"Raw\", mPara, r1,r2,r3,r4,r5,r6,r7,r8)\n",
    "        printResult(\"Entity\", mPara, e1,e2,e3,e4,e5,e6,e7,e8)\n",
    "endTime = time.time()\n",
    "print(\"total run-time\", endTime - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Jupyter Notebook into py-script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook main.ipynb to script\n",
      "[NbConvertApp] Writing 24441 bytes to main.txt\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
