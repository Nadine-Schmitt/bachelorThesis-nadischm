{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Examination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [SemanticArithmetic.py](https://github.com/Nadine-Schmitt/bachelorThesis-nadischm/blob/master/Code/SemanticArithmetic.py) script.\n",
    "\n",
    "This script train a word and entity model and do a qualitative examination afterwards.\n",
    "\n",
    "Therefore the following code reduces dimensionality of word vectors with [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) or [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). With two dimensions left, the words can be plotted as points in a two-dimensional graph by using [pythons matplotlib](https://matplotlib.org).\n",
    "\n",
    "In addition, the [most_similar() function](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar) of Gensim is used to show related words to a given word, e.g. cucumber.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[gensim](https://radimrehurek.com/gensim/), [matplotlib](https://matplotlib.org), [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html), [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html), [argparse](https://docs.python.org/3/library/argparse.html), [time](https://docs.python.org/3/library/time.html) and [multiprocessing](https://docs.python.org/3.4/library/multiprocessing.html?highlight=process) are needed for this script to work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import argparse\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage of the script can be seen with the default -h or --help flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.17134.885]\r\n",
      "(c) 2018 Microsoft Corporation. Alle Rechte vorbehalten.\r\n",
      "\r\n",
      "(base) C:\\Users\\nadin\\Documents\\Bachelorarbeit\\Code>python SemanticArithmetic.py --help\n",
      "usage: SemanticArithmetic.py [-h] [-t THREADS] source paraList\r\n",
      "\r\n",
      "Script for training word embeddings\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  source                source folder with preprocessed input data\r\n",
      "  paraList              source folder of paraList\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -t THREADS, --threads THREADS\r\n",
      "                        number of worker threads to train the model\r\n",
      "\r\n",
      "(base) C:\\Users\\nadin\\Documents\\Bachelorarbeit\\Code>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "python SemanticArithmetic.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With following function the parameter setting is read. It returns a list of lists, in which each list is a parameter setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read parameter settings and get list of lists in which each list is a parameter setting\n",
    "def readParaSetting(paraList):\n",
    "    finallist = []\n",
    "    lines = [line.rstrip('\\n') for line in open(paraList)]\n",
    "    #lines[-1] = lines[-1][0:len(lines[-1])-1]\n",
    "    for e in lines:\n",
    "        if len(e) > 0:\n",
    "            list =[]\n",
    "            listelements = e.split(' , ')\n",
    "            for i in listelements:\n",
    "                list.append(i)\n",
    "            finallist.append(list)\n",
    "    return finallist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drawing_words-function reduces the dimensionaltiy of given words either with [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) or [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) and draws the words into a diagram. \n",
    "\n",
    "Required parameters:\n",
    "- **model** which is used to visualize vectors from\n",
    "- **words** a list of words, which should be visualized\n",
    "- **pca** use PCA, if TRUE and t-SNE otherwise\n",
    "- **alternate** different color and label align is used for every second word\n",
    "- **arrows** arrows are used to connect related words (i.e. items that are next to each other in the list)\n",
    "- **x1** x axis range from\n",
    "- **x2** x axis range to\n",
    "- **y1** y axis range from\n",
    "- **y2** y axis range to\n",
    "- **title** title of the diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawing_words(saveName, model, words, pca=False, alternate=True, arrows=True, x1=3, x2=3, y1=3, y2=3, title=''):\n",
    "    # get vectors for given words from model\n",
    "    vectors = [model[word] for word in words]\n",
    "\n",
    "    #use pca\n",
    "    if pca:\n",
    "        pca = PCA(n_components=2, whiten=True)\n",
    "        vectors2d = pca.fit(vectors).transform(vectors)\n",
    "    #use t-SNE\n",
    "    else:\n",
    "        tsne = TSNE(n_components=2, random_state=0)\n",
    "        vectors2d = tsne.fit_transform(vectors)\n",
    "\n",
    "    # draw image\n",
    "    plt.figure(figsize=(6,6))\n",
    "    if pca:\n",
    "        plt.axis([x1, x2, y1, y2])\n",
    "\n",
    "    first = True # color alternation to divide given groups\n",
    "    for point, word in zip(vectors2d , words):\n",
    "        # plot points\n",
    "        plt.scatter(point[0], point[1], c='r' if first else 'g')\n",
    "        # plot word annotations\n",
    "        plt.annotate(\n",
    "            word, \n",
    "            xy = (point[0], point[1]),\n",
    "            xytext = (-7, -6) if first else (7, -6),\n",
    "            textcoords = 'offset points',\n",
    "            ha = 'right' if first else 'left',\n",
    "            va = 'bottom',\n",
    "            size = \"x-large\"\n",
    "        )\n",
    "        first = not first if alternate else first\n",
    "\n",
    "    # draw arrows\n",
    "    if arrows:\n",
    "        for i in range(0, len(words)-1, 2):\n",
    "            a = vectors2d[i][0] + 0.04\n",
    "            b = vectors2d[i][1]\n",
    "            c = vectors2d[i+1][0] - 0.04\n",
    "            d = vectors2d[i+1][1]\n",
    "            plt.arrow(a, b, c-a, d-b,\n",
    "                shape='full',\n",
    "                lw=0.1,\n",
    "                edgecolor='#bbbbbb',\n",
    "                facecolor='#bbbbbb',\n",
    "                length_includes_head=True,\n",
    "                head_width=0.08,\n",
    "                width=0.01\n",
    "            )\n",
    "\n",
    "    # draw diagram title\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #save diagram into saveName-file\n",
    "    plt.savefig(saveName, format ='png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start record time\n",
    "startTime = time.time()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Script for training word embeddings')\n",
    "parser.add_argument('source', type=str, help='source folder with preprocessed input data')\n",
    "parser.add_argument('paraList', type=str, help='source folder of paraList')\n",
    "parser.add_argument('-t', '--threads', type=int, default=mp.cpu_count(), help='number of worker threads to train the model')\n",
    "args = parser.parse_args()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input corpora for training and read parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = gensim.models.word2vec.PathLineSentences(args.source)\n",
    "\n",
    "#set parameter (read one parameter setting from a textfile)\n",
    "paraList = readParaSetting(args.paraList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model with word2vec\n",
    "#\n",
    "#for each parameter setting \n",
    "#note that here only one setting should be in list; readParaSetting is used to read the Parameter Setting from a text file)\n",
    "for e in paraList:\n",
    "    sgI = int(e[3])\n",
    "    cbowmeanI = int(e[6])\n",
    "    sizeI = int(e[0]) \n",
    "    windowI = int(e[1])\n",
    "    min_countI = int(e[2])\n",
    "    hsI = int(e[4])\n",
    "    negativeI = int(e[5]) \n",
    "        \n",
    "    model  = Word2Vec(sentences,\n",
    "                        size=sizeI,\n",
    "                        window=windowI,\n",
    "                        min_count=min_countI,\n",
    "                        workers= mp.cpu_count(),\n",
    "                        sg=sgI,\n",
    "                        hs=hsI,\n",
    "                        negative=negativeI,\n",
    "                        cbow_mean=cbowmeanI)\n",
    "\n",
    "#calculate training time and print it\n",
    "trainingTime = time.time()    \n",
    "print('model trained and it took:' , trainingTime  - startTime)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model have a high dimensional word vectors and with the drawing_words-function a list of words can be plottet.\n",
    "\n",
    "In the following 2 word classes are given, which are alternately put in a list and the alternate parameter of the function is set to TRUE in order to produce arrows. Countries and their corresponding currencies are plotted and saved into figures/currency file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot currencies\n",
    "words = [\"Switzerland\",\"franc\",\"Germany\",\"Euro\",\"England\",\"pound\",\"Japan\",\"yen\"]\n",
    "drawing_words('figures/currency', model, words, True, True, True, -3, 3, -2, 2, r'$PCA\\ Visualisierung:\\ Currencies$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following 2 word classes are given, which are alternately put in a list and the alternate parameter of the function is set to TRUE in order to produce arrows. Countries and their corresponding capitals are plotted and saved into figures/capitals file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot capitals\n",
    "words  = [\"Athens\",\"Greece\",\"Berlin\",\"Germany\",\"Paris\",\"France\",\"Bern\",\"Switzerland\",\"Vienna\",\"Austria\",\"Lisbon\",\"Portugal\",\"Moscow\",\"Russia\",\"Rome\",\"Italy\",\"Tokyo\",\"Japan\",\"London\",\"England\"]\n",
    "drawing_words('figures/capitals', model, words, True, True, True, -3, 3, -2, 2.2, r'$PCA\\ Visualisierung:\\ Capitals$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following 2 word classes are given, which are alternately put in a list and the alternate parameter of the function is set to TRUE in order to produce arrows. Countries and their corresponding languages are plotted and saved into figures/language file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot language\n",
    "words = [\"Germany\",\"German\",\"Italy\",\"Italian\",\"France\",\"French\",\"Greece\",\"Greek\",\"Spain\",\"Spanish\",\"Sweden\",\"Swedish\"]\n",
    "drawing_words('figures/language', model, words, True, True, True, -3, 3, -2, 1.7, r'$PCA\\ Visualisierung:\\ Language$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next 3 examples shows related words to a given word (tiger, cucumber and car) by using the [most_similar() function](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar) of Gensim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot related words to 'tiger' with similarity function from gensim\n",
    "matches = model.most_similar(positive=[\"tiger\"], negative=[], topn=10)\n",
    "words = [match[0] for match in matches]\n",
    "drawing_words('figures/tiger',model, words, True, False, False, -3, 2, -2, 2, r'$PCA\\ Visualisierung:\\ tiger$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot related words to 'cucumber' with similarity function from gensim\n",
    "matches = model.most_similar(positive=[\"cucumber\"], negative=[], topn=10)\n",
    "words = [match[0] for match in matches]\n",
    "drawing_words('figures/cucumber', model, words, True, False, False, -3, 2, -2, 2, r'$PCA\\ Visualisierung:\\ cucumber$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot related words to 'car' with similarity function from gensim\n",
    "matches = model.most_similar(positive=[\"car\"], negative=[], topn=10)\n",
    "words = [match[0] for match in matches]\n",
    "drawing_words('figures/cars', model, words, True, False, False, -3, 2, -2, 2, r'$PCA\\ Visualisierung:\\ car$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following the correct gender of a given name should be captured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot name\n",
    "words = [\"Annika\",\"Anton\",\"Andrea\",\"Charlotte\",\"Charles\",\"Emily\",\"Eric\",\"Florian\",\"Felix\",\"Johanna\",\"Judith\",\"Lara\",\"Julian\",\"Lea\",\"Lisa\",\"Lina\",\"Lukas\",\"Mia\",\"Nico\",\"Sophie\",\"Simon\", \"Tom\"]\n",
    "drawing_words('figures/gender', model, words, True, True, False, -3, 3, -1.5, 2.5, r'$PCA\\ Visualisierung:\\ Name\\ according to \\ gender$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total run-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endTime = time.time()\n",
    "print(\"total run-time\", endTime - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Jupyter Notebook into py-script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script SemanticArithmetic.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
